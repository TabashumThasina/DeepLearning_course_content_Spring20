{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autoencoder_dl_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd1RdewXK0VD",
        "colab_type": "code",
        "outputId": "a5909788-947e-4382-b2d0-196034bb299e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pwR4K5jLEyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bakhH4Zu1xD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhmP-Oux10Qf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import glob\n",
        "np.random.seed(1337)  \n",
        "\n",
        "\n",
        "from tensorflow.python.keras.models import Model\n",
        "from tensorflow.python.keras.layers import Input, LSTM\n",
        "from tensorflow.python.keras.utils import np_utils\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import datetime\n",
        "now = datetime.datetime.now\n",
        "\n",
        "batch_size = 10\n",
        "\n",
        "# length of data sequences\n",
        "n_timesteps = 240\n",
        "# dimension of data sequences\n",
        "n_dim = 117"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj7wNyb934eD",
        "colab_type": "text"
      },
      "source": [
        "# 1. Loading Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRNwoQgd13gI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reading_files():\n",
        "    all_files_corrected = glob.glob(\"/content/drive/My Drive/DeepLearningProject/Segmented Movements/Data_Proccessed/Corrected/Vicon/Positions/*.csv\")\n",
        "    all_files_incorrected = glob.glob(\"/content/drive/My Drive/DeepLearningProject/Segmented Movements/Data_Proccessed/Incorrected/Vicon/Positions/*.csv\")\n",
        "    return all_files_corrected,all_files_incorrected"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "np9CtEGm15do",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_files_corrected , all_files_incorrected =reading_files()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foBGZqFi17Bo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_files_corrected = sorted(all_files_corrected)\n",
        "all_files_incorrected = sorted(all_files_incorrected)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICUiKMKz18nv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "def load_data(corrected_file, incorrected_file):\n",
        "    f = open( corrected_file )\n",
        "    csv_f = csv.reader(f)\n",
        "    X_Corr = list(csv_f)\n",
        "\n",
        "    # Convert the input sequences into numpy arrays\n",
        "    train_input1 = np.asarray(X_Corr)\n",
        "    n_dim = 117\n",
        "    data_correct = np.zeros((90,240,n_dim))\n",
        "    for i in range(len(train_input1)//n_dim):\n",
        "          data_correct[i,:,:] = np.transpose(train_input1[n_dim*i:n_dim*(i+1),:])\n",
        "    \n",
        "    f = open( incorrected_file )\n",
        "    csv_f = csv.reader(f)\n",
        "    X_Incor = list(csv_f)\n",
        "\n",
        "    # Convert the input sequences into numpy arrays\n",
        "    train_input2 = np.asarray(X_Incor)\n",
        "    n_dim = 117\n",
        "    data_incorrect = np.zeros((90,240,n_dim))\n",
        "    for i in range(len(train_input2)//n_dim):\n",
        "          data_incorrect[i,:,:] = np.transpose(train_input2[n_dim*i:n_dim*(i+1),:])\n",
        "    \n",
        "    return data_correct, data_incorrect"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoZ26aLZ1_Tn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "exercises_names = [ \"deep squat\",\n",
        "                   \"hurdle step\",\n",
        "                   \"inline lunge\",\n",
        "                   \"side lunge\",\n",
        "                   \"sit to stand\",\n",
        "                   \"standing active straight leg raise\",\n",
        "                   \"standing shoulder abduction\",\n",
        "                   \"standing shoulder extension\",\n",
        "                   \"standing shoulder internal-external rotation\",\n",
        "                   \"standing shoulder scaption\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7ec8DSb2C3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(all_files_incorrected),len(all_files_corrected),len(exercises_names))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX7_5VA-2G_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_setting(index):\n",
        "  X_correct, X_incorrect = load_data(all_files_corrected[index],all_files_incorrected[index])\n",
        "  data_correct = np.zeros((X_correct.shape[0],n_timesteps+100,n_dim))\n",
        "  for i in range(X_correct.shape[0]):\n",
        "      data_correct[i,:,:] = np.concatenate((np.concatenate((np.tile(X_correct[i,0,:],[50, 1]), X_correct[i,:,:])), np.tile(X_correct[i,-1,:],[50, 1])))\n",
        "\n",
        "  data_incorrect = np.zeros((X_incorrect.shape[0],n_timesteps+100,n_dim))\n",
        "  for i in range(X_incorrect.shape[0]):\n",
        "      data_incorrect[i,:,:] = np.concatenate((np.concatenate((np.tile(X_incorrect[i,0,:],[50, 1]), X_incorrect[i,:,:])), np.tile(X_incorrect[i,-1,:],[50, 1])))\n",
        "  return data_correct,data_incorrect"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnF8gc614Pf3",
        "colab_type": "text"
      },
      "source": [
        "# 2. Processing of Sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l6WWePc2DR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def adding_frames(X_correct,X_incorrect, exercise_num ):\n",
        "    # Add 50 time frames at the beginning and end of sequences\n",
        "  # The autoencoder has difficulties with the beginning and ending frames\n",
        "  data_correct = np.zeros((X_correct.shape[0],n_timesteps+100,n_dim))\n",
        "  for i in range(X_correct.shape[0]):\n",
        "      data_correct[i,:,:] = np.concatenate((np.concatenate((np.tile(X_correct[i,0,:],[50, 1]), X_correct[i,:,:])), np.tile(X_correct[i,-1,:],[50, 1])))\n",
        "\n",
        "  data_incorrect = np.zeros((X_incorrect.shape[0],n_timesteps+100,n_dim))\n",
        "  for i in range(X_incorrect.shape[0]):\n",
        "      data_incorrect[i,:,:] = np.concatenate((np.concatenate((np.tile(X_incorrect[i,0,:],[50, 1]), X_incorrect[i,:,:])), np.tile(X_incorrect[i,-1,:],[50, 1])))\n",
        "      \n",
        "  # Plot the first sequences of correct and incorrect data\n",
        "  plt.figure(figsize = (12,6))\n",
        "  # plt.title()\n",
        "  ax = plt.subplot(1,2,1)\n",
        "  ax.set_title(' Sequence of correct data  for exercise \\n'+exercises_names[exercise_num] ,fontweight='bold') \n",
        "  plt.plot(data_correct[0])\n",
        "  plt.ylim([-1,1])\n",
        "  ax2 = plt.subplot(1,2,2)\n",
        "  ax2.set_title(' Sequence of incorrect data for exercise \\n'+exercises_names[exercise_num] ,fontweight='bold') \n",
        "  plt.plot(data_incorrect[0])\n",
        "  plt.ylim([-1,1])\n",
        "  plt.tight_layout()\n",
        "  plt.savefig(\"/content/drive/My Drive/DeepLearningProject/Figures/pos_m0\"+str(exercise_num+1)+\".png\",bbox_inches='tight')\n",
        "  plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYHO1zhx2E73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sequence_of_the_exercises(files_corrected,files_incorrected , exercise_num):\n",
        "  X_correct, X_incorrect = load_data( files_corrected , files_incorrected)\n",
        "  print(X_correct.shape, 'correct sequences')\n",
        "  print(X_incorrect.shape, 'incorrect sequences')\n",
        "\n",
        "  # Plot the first sequences of correct and incorrect data\n",
        "  plt.figure(figsize = (12,6))\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.plot(X_correct[0])\n",
        "  plt.ylim([-1,1])\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.plot(X_incorrect[0])\n",
        "  plt.ylim([-1,1])\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "  # adding_frames(X_correct,X_incorrect ,exercise_num )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJ1q5C-o4CXg",
        "colab_type": "text"
      },
      "source": [
        "# 3. Model Building\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqBuTeqI2JhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Encoder layers\n",
        "input_seq = Input(shape=(n_timesteps+100,n_dim))\n",
        "encoded1 = LSTM(30,return_sequences = True)(input_seq)\n",
        "encoded2 = LSTM(10,return_sequences = True)(encoded1)\n",
        "# Encoded representation of the input, 340x4 vector\n",
        "encoded = LSTM(4,return_sequences = True)(encoded2)\n",
        "# Decoder layers\n",
        "decoded1 = LSTM(10,return_sequences = True)(encoded)\n",
        "decoded2 = LSTM(30,return_sequences = True)(decoded1)\n",
        "decoded = LSTM(n_dim, return_sequences = True)(decoded2)\n",
        "\n",
        "# The model maps an input to its reconstruction\n",
        "autoencoder = Model(inputs=input_seq, outputs=decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "autoencoder.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQLMw26r2VX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(history , index):\n",
        "  from google.colab import files\n",
        "  plt.figure()\n",
        "  plt.subplot(121)\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.title('Loss for \\n'+str(exercises_names[index]))\n",
        "  plt.subplot(122)\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('Validation Loss for \\n'+str(exercises_names[index]))\n",
        "  plt.tight_layout()\n",
        "  plt.savefig(\"/content/drive/My Drive/DeepLearningProject/Figures/loss_pos_m0\"+str(index+1)+\".png\",bbox_inches='tight')\n",
        "  plt.show()\n",
        "  #files.download('/content/drive/My Drive/DeepLearningProject/Figures/loss_m0'+str(index+1)+'.png')\n",
        "  # Print the resulting training and validation loss values\n",
        "  print(history.history['loss'][-1])\n",
        "  print(history.history['val_loss'][-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAVugX5F2Xpg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_Sequence_Plot(decoded_seqs,index,data_correct):\n",
        "  \n",
        "  # Plot the results\n",
        "  n = 2  # how many sequences we will display\n",
        "  plt.figure(figsize = (12,6))\n",
        "  for i in range(n):\n",
        "      # display original sequences\n",
        "      plt.subplot(n, 2, 2*i+1)\n",
        "      plt.plot(data_correct[i])\n",
        "      plt.title('original sequences \\n'+str(exercises_names[index]))\n",
        "      # display reconstruction\n",
        "      plt.subplot(n, 2, 2*i+2)\n",
        "      plt.plot(decoded_seqs[i])\n",
        "      plt.title('decoded sequences \\n'+str(i+1)+\" : \"+str(exercises_names[index]))\n",
        "  plt.tight_layout()\n",
        "  plt.savefig(\"/content/drive/My Drive/DeepLearningProject/Figures/original_seq_vs_decoded_seq_pos_m0\"+str(index+1)+\".png\",bbox_inches='tight')\n",
        "  #files.download(\"/content/drive/My Drive/DeepLearningProject/Figures/original_seq_vs_decoded_seq_m0\"+str(index+1)+\".png\")\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH547ObC2eJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoded_sequence_plot(encoded_seqs,index,data_correct):\n",
        "  # Plot the results\n",
        "  n = 2  # how many sequences we will display\n",
        "  plt.figure(figsize = (12,6))\n",
        "  for i in range(n):\n",
        "      # display original sequences\n",
        "      plt.subplot(n, 2, 2*i+1)\n",
        "      plt.plot(data_correct[i])\n",
        "      plt.title('original sequences \\n'+str(exercises_names[index]))\n",
        "      # display reconstruction\n",
        "      plt.subplot(n, 2, 2*i+2)\n",
        "      plt.plot(encoded_seqs[i])\n",
        "      plt.title('encoded sequences \\n'+str(i+1)+\" :\"+str(exercises_names[index]))\n",
        "  plt.tight_layout()\n",
        "  plt.savefig(\"/content/drive/My Drive/DeepLearningProject/Figures/original_seq_vs_encoded_seq_pos_m0\"+str(index+1)+\".png\",bbox_inches='tight')\n",
        "  #files.download(\"/content/drive/My Drive/DeepLearningProject/Figures/original_seq_vs_encoded_seq_m0\"+str(index+1)+\".png\")\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO8m815a2ew_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def time_frame_autencoder_plot(encoded_seqs,index,data_correct):\n",
        "  plt.figure(figsize = (14,14))\n",
        "  for i in range(data_correct.shape[0]):\n",
        "      plt.subplot(4,1,1)\n",
        "      plt.plot(encoded_seqs[i,50:-50,0])\n",
        "      plt.xlabel('Time Frame',fontsize=12)\n",
        "      plt.ylabel('Angle (Degrees)',fontsize=12)\n",
        "      plt.subplot(4,1,2)\n",
        "      plt.plot(encoded_seqs[i,50:-50,1])\n",
        "      plt.xlabel('Time Frame',fontsize=12)\n",
        "      plt.ylabel('Angle (Degrees)',fontsize=12)\n",
        "      plt.subplot(4,1,3)\n",
        "      plt.plot(encoded_seqs[i,50:-50,2])\n",
        "      plt.xlabel('Time Frame',fontsize=12)\n",
        "      plt.ylabel('Angle (Degrees)',fontsize=12)\n",
        "      plt.subplot(4,1,4)\n",
        "      plt.plot(encoded_seqs[i,50:-50,3])\n",
        "      plt.xlabel('Time Frame',fontsize=12)\n",
        "      plt.ylabel('Angle (Degrees)',fontsize=12)\n",
        "  plt.tight_layout()\n",
        "  plt.savefig(\"/content/drive/My Drive/DeepLearningProject/Figures/autoencoder_output_pos_m0\"+str(index+1)+\".png\",bbox_inches='tight')\n",
        "  #files.download(\"/content/drive/My Drive/DeepLearningProject/Figures/autoencoder_output_m0\"+str(index+1)+\".png\")\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi7PpMPD2hMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def running_models(index):\n",
        "  data_correct , data_incorrect = data_setting(index)\n",
        "  import random\n",
        "  trainidx = random.sample(range(0,data_correct.shape[0]),63)\n",
        "  valididx = np.setdiff1d(np.arange(0,90,1),trainidx)\n",
        "  train_data = data_correct[trainidx,:,:]\n",
        "  valid_data = data_correct[valididx,:,:]\n",
        "  import os\n",
        "  # Directory where the checkpoints will be saved\n",
        "  # checkpoint_dir = '/content/drive/My Drive/DeepLearningProject/trainingcheckpoints/m0'+str(index+1)\n",
        "  # # Name of the checkpoint files\n",
        "  # checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "  # checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "  #     filepath=checkpoint_prefix,\n",
        "  #     save_weights_only=True)\n",
        "  \n",
        "  # Train an autoencoder on the correct data sequences\n",
        "\n",
        "  # Measure the training time \n",
        "  t = now()\n",
        "\n",
        "  # Request to stop before reaching the number of epochs if the validation loss does not decrease for 1000 epochs\n",
        "  early_stopping = EarlyStopping(monitor='val_loss', patience = 1000)\n",
        "\n",
        "  history = autoencoder.fit(train_data, train_data, epochs = 10000, batch_size = batch_size, shuffle=True,\n",
        "                  validation_data=(valid_data, valid_data), verbose = 0, callbacks = [early_stopping])\n",
        "\n",
        "  print('Training time: %s' % (now() - t))\n",
        "  loss(history,index)\n",
        "\n",
        "  # Encode and decode sequences to check the model performance\n",
        "  decoded_seqs = autoencoder.predict(data_correct)\n",
        "  decode_Sequence_Plot(decoded_seqs,index,data_correct)\n",
        "    # Create an encoder model, that maps an input to its encoded representation\n",
        "  encoder = Model(inputs=input_seq, outputs=encoded)\n",
        "\n",
        "  # Test the encoder model\n",
        "  encoded_seqs = encoder.predict(data_correct)\n",
        "\n",
        "  encoded_sequence_plot(encoded_seqs,index,data_correct)\n",
        "  time_frame_autencoder_plot(encoded_seqs,index,data_correct)\n",
        "  \n",
        "  # Remove the added first and last 50 frames \n",
        "  encoded_seqs = encoded_seqs[:,50:-50,:]\n",
        "\n",
        "  print(encoded_seqs.shape, 'encoded sequences shape')\n",
        "  # Reshape the encoded sequences, because savetxt saves two dimensional data\n",
        "  seqs = encoded_seqs.reshape(encoded_seqs.shape[0],encoded_seqs.shape[1]*encoded_seqs.shape[2])\n",
        "  print(seqs.shape, 'encoded sequences shape for saving')\n",
        "  # Save the data in the file 'Autoencoder_Output_Correct.csv'\n",
        "  np.savetxt('/content/drive/My Drive/DeepLearningProject/Segmented Movements/Data_Proccessed/Corrected/Vicon/Angles/Autoencoder/Autoencoder_Output_Correct_pos_m0'+str(index+1)+'.csv', seqs, fmt='%.5f',delimiter=',')\n",
        "  #files.download('/content/drive/My Drive/DeepLearningProject/Segmented Movements/Data_Proccessed/Corrected/Vicon/Angles/Autoencoder/Autoencoder_Output_Correct_m0'+str(index+1)+'.csv')\n",
        "\n",
        "  # Reduce the dimensionality of the incorrect sequences\n",
        "  encoded_seqs_incorrect = encoder.predict(data_incorrect)\n",
        "  \n",
        "  # Remove the added first and last 50 frames \n",
        "  encoded_seqs_incorrect = encoded_seqs_incorrect[:,50:-50,:]\n",
        "\n",
        "  print(encoded_seqs_incorrect.shape, 'encoded incorrect sequences shape')\n",
        "  # Reshape the encoded sequences, because savetxt saves only tow dimensional data\n",
        "  seqs_incorrect = encoded_seqs_incorrect.reshape(encoded_seqs_incorrect.shape[0],encoded_seqs_incorrect.shape[1]*encoded_seqs_incorrect.shape[2])\n",
        "  print(seqs_incorrect.shape, 'encoded incorrect sequences shape for saving')\n",
        "  # Save the incorrect data in the file 'Autoencoder_Output_Incorrect.csv'\n",
        "  np.savetxt('/content/drive/My Drive/DeepLearningProject/Segmented Movements/Data_Proccessed/Incorrected/Vicon/Angles/Autoencoder/Autoencoder_Output_Incorrect_pos_m0'+str(index+1)+'.csv', seqs_incorrect, fmt='%.5f',delimiter=',')\n",
        "  #files.download('/content/drive/My Drive/DeepLearningProject/Segmented Movements/Data_Proccessed/Incorrected/Vicon/Angles/Autoencoder/Autoencoder_Output_Incorrect_m0'+str(index+1)+'.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zM8JVFQ2r9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(0,10):\n",
        "  running_models(i)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}