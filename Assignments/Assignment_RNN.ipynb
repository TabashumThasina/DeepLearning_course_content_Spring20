{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thasina Tabashum\n",
    "# Farhad Mokter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1115394 characters\n"
     ]
    }
   ],
   "source": [
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print ('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 250 characters in text\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 unique characters\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  '\\n':   0,\n",
      "  ' ' :   1,\n",
      "  '!' :   2,\n",
      "  '$' :   3,\n",
      "  '&' :   4,\n",
      "  \"'\" :   5,\n",
      "  ',' :   6,\n",
      "  '-' :   7,\n",
      "  '.' :   8,\n",
      "  '3' :   9,\n",
      "  ':' :  10,\n",
      "  ';' :  11,\n",
      "  '?' :  12,\n",
      "  'A' :  13,\n",
      "  'B' :  14,\n",
      "  'C' :  15,\n",
      "  'D' :  16,\n",
      "  'E' :  17,\n",
      "  'F' :  18,\n",
      "  'G' :  19,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'First Citizen' ---- characters mapped to int ---- > [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
     ]
    }
   ],
   "source": [
    "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100\n",
    "examples_per_epoch = len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\n",
      "i\n",
      "r\n",
      "s\n",
      "t\n"
     ]
    }
   ],
   "source": [
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "  print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
      "'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
      "\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
      "\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
      "'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "  print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
      "Target data: 'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 18 ('F')\n",
      "  expected output: 47 ('i')\n",
      "Step    1\n",
      "  input: 47 ('i')\n",
      "  expected output: 56 ('r')\n",
      "Step    2\n",
      "  input: 56 ('r')\n",
      "  expected output: 57 ('s')\n",
      "Step    3\n",
      "  input: 57 ('s')\n",
      "  expected output: 58 ('t')\n",
      "Step    4\n",
      "  input: 58 ('t')\n",
      "  expected output: 1 (' ')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.GRU(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "  example_batch_predictions = model(input_example_batch)\n",
    "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           16640     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 65)            66625     \n",
      "=================================================================\n",
      "Total params: 4,021,569\n",
      "Trainable params: 4,021,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([54, 41, 32,  5, 61, 19,  3, 35, 25, 16,  2, 44, 58, 38, 62, 16, 22,\n",
       "       40, 43, 18, 60,  1, 32, 14, 13, 27, 33, 24, 55,  6, 61,  8, 29, 22,\n",
       "       10, 53, 16,  0,  4, 23, 63, 47,  7, 32, 17, 24, 42, 57,  5, 59, 42,\n",
       "       15, 52, 62, 41,  6, 25, 40, 64, 61, 59,  2, 33, 47, 20, 62, 23,  7,\n",
       "       13, 17, 55, 49, 21, 57, 19, 48, 35, 63, 35, 19,  3, 56, 53, 45, 39,\n",
       "       33, 29, 46, 50, 19, 57, 18,  4, 42, 59, 53, 43, 61, 10, 58],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " 'to thee shall be my study, and my profit\\ntherein the heaping friendships. Of that fatal\\ncountry, Sic'\n",
      "\n",
      "Next Char Predictions: \n",
      " \"pcT'wG$WMD!ftZxDJbeFv TBAOULq,w.QJ:oD\\n&Kyi-TELds'udCnxc,Mbzwu!UiHxK-AEqkIsGjWyWG$rogaUQhlGsF&duoew:t\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 65)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.1747746\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 172 steps\n",
      "Epoch 1/10\n",
      "172/172 [==============================] - 239s 1s/step - loss: 2.4754\n",
      "Epoch 2/10\n",
      "172/172 [==============================] - 243s 1s/step - loss: 1.9331\n",
      "Epoch 3/10\n",
      "172/172 [==============================] - 245s 1s/step - loss: 1.6814\n",
      "Epoch 4/10\n",
      "172/172 [==============================] - 249s 1s/step - loss: 1.5386\n",
      "Epoch 5/10\n",
      "172/172 [==============================] - 252s 1s/step - loss: 1.4517\n",
      "Epoch 6/10\n",
      "172/172 [==============================] - 249s 1s/step - loss: 1.3928\n",
      "Epoch 7/10\n",
      "172/172 [==============================] - 250s 1s/step - loss: 1.3483\n",
      "Epoch 8/10\n",
      "172/172 [==============================] - 235s 1s/step - loss: 1.3096\n",
      "Epoch 9/10\n",
      "172/172 [==============================] - 235s 1s/step - loss: 1.2759\n",
      "Epoch 10/10\n",
      "172/172 [==============================] - 236s 1s/step - loss: 1.2427\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints\\\\ckpt_10'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            16640     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 65)             66625     \n",
      "=================================================================\n",
      "Total params: 4,021,569\n",
      "Trainable params: 4,021,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "  # Evaluation step (generating text using the learned model)\n",
    "\n",
    "  # Number of characters to generate\n",
    "  num_generate = 1000\n",
    "\n",
    "  # Converting our start string to numbers (vectorizing)\n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty string to store our results\n",
    "  text_generated = []\n",
    "\n",
    "  # Low temperatures results in more predictable text.\n",
    "  # Higher temperatures results in more surprising text.\n",
    "  # Experiment to find the best setting.\n",
    "  temperature = 1.0\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      # remove the batch dimension\n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # using a categorical distribution to predict the character returned by the model\n",
    "      predictions = predictions / temperature\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # We pass the predicted character as the next input to the model\n",
    "      # along with the previous hidden state\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "      text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO: he doth damn dews:\n",
      "Swell so much to three battless Townr hath paled\n",
      "With tends such father, fellows have; prepostering hite.\n",
      "FartIUS:\n",
      "Hen she durst wince that singuless clear\n",
      "Has there, to purpose must. His raje to break them, live\n",
      "Lad has put in thee, take themoster; if your battle looks,\n",
      "I could say a few word and by my erges:\n",
      "At the world I blast too, bring me little vols was:\n",
      "The worsher laid or time, not any upproverbid,\n",
      "Hast thou, give him. I have avide!\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "By the northere, very tomongs, so till they know no more strong hath jost before him;\n",
      "And to Our house:\n",
      "And heish one war nor hath their plain stabb'd your paper.\n",
      "And, of firtt to thee sweet; to pread it,\n",
      "That up Northumberland's most royal kiss,\n",
      "That naught have strong a person read.\n",
      "\n",
      "MARCIUS:\n",
      "Nay, I hear upon my blood,\n",
      "You have empounded vary marrian wishing hither;\n",
      "And put you may the sacred vault,\n",
      "I'll raised villains they are too cauntaily?\n",
      "\n",
      "PRINCEPERET:\n",
      "What, wish! the scandon your country may must give th\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"ROMEO: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_lstm(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.LSTM(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = build_model_lstm(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (64, None, 256)           16640     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (64, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (64, None, 65)            66625     \n",
      "=================================================================\n",
      "Total params: 5,330,241\n",
      "Trainable params: 5,330,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir2 = './training_checkpoints_lstm'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix2 = os.path.join(checkpoint_dir2, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback2=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix2,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 172 steps\n",
      "Epoch 1/10\n",
      "172/172 [==============================] - 312s 2s/step - loss: 2.4616\n",
      "Epoch 2/10\n",
      "172/172 [==============================] - 315s 2s/step - loss: 1.8867\n",
      "Epoch 3/10\n",
      "172/172 [==============================] - 339s 2s/step - loss: 1.6533\n",
      "Epoch 4/10\n",
      "172/172 [==============================] - 313s 2s/step - loss: 1.5212\n",
      "Epoch 5/10\n",
      "172/172 [==============================] - 316s 2s/step - loss: 1.4406\n",
      "Epoch 6/10\n",
      "172/172 [==============================] - 321s 2s/step - loss: 1.3842\n",
      "Epoch 7/10\n",
      "172/172 [==============================] - 318s 2s/step - loss: 1.3402\n",
      "Epoch 8/10\n",
      "172/172 [==============================] - 316s 2s/step - loss: 1.3016\n",
      "Epoch 9/10\n",
      "172/172 [==============================] - 318s 2s/step - loss: 1.2688\n",
      "Epoch 10/10\n",
      "172/172 [==============================] - 317s 2s/step - loss: 1.2347\n"
     ]
    }
   ],
   "source": [
    "history3 = model2.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints_lstm\\\\ckpt_10'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = build_model_lstm(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model2.load_weights(tf.train.latest_checkpoint(checkpoint_dir2))\n",
    "\n",
    "model2.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing between two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_loss = history.history['loss']\n",
    "model2_loss = history3.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epoch_count = range(1, len(model1_loss)+1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, model2_loss, 'r-')\n",
    "plt.plot(epoch_count, model1_loss, 'b-')\n",
    "plt.legend(['LSTM_Loss','GUR_Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_file = open(\"names.txt\",encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1284899 characters\n"
     ]
    }
   ],
   "source": [
    "print ('Length of text: {} characters'.format(len(names_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "a'isha\n",
      "a'ishah\n",
      "a-jay\n",
      "aa'isha\n",
      "aa'ishah\n",
      "aaban\n",
      "aabas\n",
      "aabha\n",
      "aabia\n",
      "aabid\n",
      "aabidah\n",
      "aab\n"
     ]
    }
   ],
   "source": [
    "print(names_file[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 unique characters\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(names_file))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "char2idx_n = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char_n = np.array(vocab)\n",
    "\n",
    "text_as_int_n = np.array([char2idx_n[c] for c in names_file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  '\\n':   0,\n",
      "  '&' :   1,\n",
      "  \"'\" :   2,\n",
      "  '(' :   3,\n",
      "  ')' :   4,\n",
      "  '-' :   5,\n",
      "  '/' :   6,\n",
      "  '0' :   7,\n",
      "  '8' :   8,\n",
      "  '[' :   9,\n",
      "  'a' :  10,\n",
      "  'b' :  11,\n",
      "  'c' :  12,\n",
      "  'd' :  13,\n",
      "  'e' :  14,\n",
      "  'f' :  15,\n",
      "  'g' :  16,\n",
      "  'h' :  17,\n",
      "  'i' :  18,\n",
      "  'j' :  19,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx_n, range(20)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx_n[char]))\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'-------------' ---- characters mapped to int ---- > [5 5 5 5 5 5 5 5 5 5 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "print ('{} ---- characters mapped to int ---- > {}'.format(repr(names_file[:13]), text_as_int_n[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 10\n",
    "examples_per_epoch = len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "char_dataset_n = tf.data.Dataset.from_tensor_slices(text_as_int_n)\n",
    "\n",
    "for i in char_dataset_n.take(5):\n",
    "  print(idx2char_n[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'-----------'\n",
      "'---------\\na'\n",
      "\"'isha\\na'ish\"\n",
      "'ah\\na-jay\\naa'\n",
      "\"'isha\\naa'is\"\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset_n.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "  print(repr(''.join(idx2char_n[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target_names(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset_n = sequences.map(split_input_target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  '----------'\n",
      "Target data: '----------'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset_n.take(1):\n",
    "  print ('Input data: ', repr(''.join(idx2char_n[input_example.numpy()])))\n",
    "  print ('Target data:', repr(''.join(idx2char_n[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 5 ('-')\n",
      "  expected output: 5 ('-')\n",
      "Step    1\n",
      "  input: 5 ('-')\n",
      "  expected output: 5 ('-')\n",
      "Step    2\n",
      "  input: 5 ('-')\n",
      "  expected output: 5 ('-')\n",
      "Step    3\n",
      "  input: 5 ('-')\n",
      "  expected output: 5 ('-')\n",
      "Step    4\n",
      "  input: 5 ('-')\n",
      "  expected output: 5 ('-')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char_n[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char_n[target_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset_n = dataset_n.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size_n = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_new(vocab_size_n, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size_n, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.GRU(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size_n)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = build_model_new(\n",
    "  vocab_size_n = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 10, 137) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset_n.take(1):\n",
    "  example_batch_predictions = model_new(input_example_batch)\n",
    "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (256, None, 256)          35072     \n",
      "_________________________________________________________________\n",
      "gru_9 (GRU)                  (256, None, 1024)         3938304   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (256, None, 137)          140425    \n",
      "=================================================================\n",
      "Total params: 4,113,801\n",
      "Trainable params: 4,113,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 56,  82,  77,  30,  47,  54,  96, 107,  44,   7], dtype=int64)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (256, 10, 137)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.9228454\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir_n = './training_checkpoints_names'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback_n=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 456 steps\n",
      "Epoch 1/10\n",
      "456/456 [==============================] - 168s 369ms/step - loss: 2.4928\n",
      "Epoch 2/10\n",
      "456/456 [==============================] - 174s 382ms/step - loss: 2.2502\n",
      "Epoch 3/10\n",
      "456/456 [==============================] - 170s 372ms/step - loss: 2.1630\n",
      "Epoch 4/10\n",
      "456/456 [==============================] - 173s 380ms/step - loss: 2.1024\n",
      "Epoch 5/10\n",
      "456/456 [==============================] - 187s 410ms/step - loss: 2.0598\n",
      "Epoch 6/10\n",
      "456/456 [==============================] - 174s 382ms/step - loss: 2.0294\n",
      "Epoch 7/10\n",
      "456/456 [==============================] - 175s 384ms/step - loss: 2.0059\n",
      "Epoch 8/10\n",
      "456/456 [==============================] - 173s 380ms/step - loss: 1.9881\n",
      "Epoch 9/10\n",
      "456/456 [==============================] - 175s 384ms/step - loss: 1.9726\n",
      "Epoch 10/10\n",
      "456/456 [==============================] - 177s 387ms/step - loss: 1.9618\n"
     ]
    }
   ],
   "source": [
    "history_new = model_new.fit(dataset_n, epochs=EPOCHS, callbacks=[checkpoint_callback_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints_names\\\\ckpt_10'"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = build_model(vocab_size_n, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model_new.load_weights(tf.train.latest_checkpoint(checkpoint_dir_n))\n",
    "\n",
    "model_new.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (1, None, 256)            35072     \n",
      "_________________________________________________________________\n",
      "gru_10 (GRU)                 (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (1, None, 137)            140425    \n",
      "=================================================================\n",
      "Total params: 4,113,801\n",
      "Trainable params: 4,113,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_count = range(1, len(history_new.history['loss'])+1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, history_new.history['loss'], 'r-')\n",
    "\n",
    "plt.legend(['Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
